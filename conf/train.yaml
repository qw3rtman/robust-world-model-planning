defaults:
  - _self_
  - env: pusht
  - encoder: dino
  - action_encoder: proprio
  - proprio_encoder: proprio
  - decoder: vqvae
  - predictor: vit
  - initnet: mlp
  - override hydra/launcher: submitit_slurm

# checkpoints will be loaded from ckpt_path/checkpoints/
ckpt_path: "./outputs/pusht/"

hydra:
  run:
    dir: ${ckpt_path}/${method}/${now:%Y-%m-%d}/${now:%H-%M-%S}

training:
  seed: 0
  epochs: 100
  batch_size: 8 # should >= nodes * tasks_per_node
  pretrain_batch_size: 32
  save_every_x_epoch: 1
  save_every_x_batch: 50
  reconstruct_every_x_batch: 500
  num_reconstruct_samples: 6
  encoder_lr: 1e-6
  decoder_lr: 3e-4
  predictor_lr: 1e-5
  action_encoder_lr: 5e-4
  initnet_lr: 5e-4
  inner_lr: 1e-1

N: 5
K: 5
val_rollout_steps: 100

method: adversarial # adversarial | online | offline (teacher-forcing)

# online parameters
replay_buffer_frequency: 10

# adversarial parameters
radii_method: adaptive # adaptive | fixed
visual_eps_factor: 0.05
proprio_eps_factor: 0.02
action_eps_factor: 0.02

img_size: 224 # should be a multiple of 224
frameskip: 5
concat_dim: 1

normalize_action: True

# action encoder
action_emb_dim: 10
num_action_repeat: 1

# proprio encoder
proprio_emb_dim: 10 
num_proprio_repeat: 1

num_hist: 3 # 1 for wall; 3 for pusht/pointmaze
num_pred: 1 # only supports 1
has_predictor: True # set this to False for only training a decoder
has_decoder: True # set this to False for only training a predictor

has_innerloop: False
inner_iters: 3
inner_scale: 1e-1

model:
  _target_: models.visual_world_model.VWorldModel
  image_size: ${img_size}
  num_hist: ${num_hist}
  num_pred: ${num_pred}
  train_encoder: False
  train_predictor: True
  train_decoder: True
  train_initnet: False

debug: False 

# Planning params for planning eval jobs launched during training
plan_settings: 
  # plan_cfg_path: conf/plan.yaml # set to null for no planning evals
  plan_cfg_path: null 
  planner: ['gd', 'cem']
  goal_source: ['dset', 'random_state']
  goal_H: [5]
  alpha: [0.1, 1]